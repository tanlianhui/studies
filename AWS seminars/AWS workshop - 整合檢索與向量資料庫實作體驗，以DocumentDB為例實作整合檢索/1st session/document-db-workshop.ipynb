{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries needed for this lab. \n",
    "\n",
    "1. pymongo: a python driver that gives access to DocumentDB clusters\n",
    "2. boto3: the AWS sdk that allows you access services programatically \n",
    "3. json: a native library to work with json data\n",
    "4. pandas: a Python library that helps with data analysis and manipulation: \n",
    "5. langchain: an open-source framework that allows developers to build applications using large language models (LLMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the Libraries\n",
    "import pymongo\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd \n",
    "import gradio as gr\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_community.vectorstores.documentdb import DocumentDBVectorSearch\n",
    "from langchain_community.vectorstores.documentdb import DocumentDBSimilarityType\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from botocore.exceptions import ClientError\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connecting to DocumentDB cluster. Required parameters:\n",
    "\n",
    "1. Documentdb cluster indentifier\n",
    "2. Username created for lab\n",
    "3. password created for lab\n",
    "\n",
    "For more information see: \n",
    "\n",
    "https://docs.aws.amazon.com/documentdb/latest/developerguide/connect_programmatically.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5819/1485991547.py:2: UserWarning: You appear to be connected to a DocumentDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/documentdb\n",
      "  client = pymongo.MongoClient(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'version': '5.0.0',\n",
       " 'versionArray': [5, 0, 0, 0],\n",
       " 'bits': 64,\n",
       " 'maxBsonObjectSize': 16777216,\n",
       " 'ok': 1.0,\n",
       " 'operationTime': Timestamp(1746772379, 1)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connecting to DocumentDB Cluster\n",
    "client = pymongo.MongoClient(\n",
    "\"workshop-cloudformation-documentdb.cluster-cjqqqo2wky0f.us-west-2.docdb.amazonaws.com:27017\",\n",
    "username=\"Labuser\",\n",
    "password=\"PgXYh-~j37%LaFgy\",\n",
    "retryWrites=False,\n",
    "tls='true',\n",
    "tlsCAFile=\"global-bundle.pem\")\n",
    "\n",
    "client.server_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a database and collection with the existing DocumentDB connection.\n",
    "\n",
    "Required paramenters:\n",
    "\n",
    "    1. Database Name\n",
    "    2. Collection Name\n",
    "\n",
    "The current cell below will create a database named \"workshopdatabase\" and a collection named \"workshopcollection\"\n",
    "    \n",
    "    https://www.w3schools.com/python/python_mongodb_create_db.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create database/collection\n",
    "db = client[\"workshopdatabase\"]\n",
    "collection = db[\"workshopcollection\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading movie data from the 'movies_metadata_new.csv' and inserting it into the DocumentDB collection created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data has been successfully uploaded to DocumentDB\n"
     ]
    }
   ],
   "source": [
    "# Loading the DocumentDB database from the example dataset in csv\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file = \"movie_data.csv\" \n",
    "data = pd.read_csv(csv_file)\n",
    "# Convert the DataFrame to a list of dictionaries (one per row)\n",
    "data_dict = data.to_dict(orient=\"records\")\n",
    "# Insert the data into the MongoDB collection\n",
    "collection.insert_many(data_dict)\n",
    "print(\"CSV data has been successfully uploaded to DocumentDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing a bedrock client through boto3 that allows api calls to be made to Bedrock\n",
    "For more information: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime.html\n",
    "\n",
    "The default value for this workshop is set to us-west-2, please replace this with the value of region you are running this workshop in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Starting the bedrock client\n",
    "bedrock_client = boto3.client('bedrock-runtime','us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that utilizes the client above to access the amazon titan embeddings model to create embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining Bedrock model parameters\n",
    "modelId = \"amazon.titan-embed-text-v1\"  # (Change this to try different embedding models)\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "#Define Generate Embedding Function\n",
    "def generate_embedding(text):\n",
    "    body = json.dumps({\"inputText\": text})\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "checking to see if thefunction works replace '<text>' with any word of your choice to see the created embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking if Bedrock is generating embeddings\n",
    "generate_embedding(\"mouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating embeddings for the 'overview' field of the movie data to allow. We will then update each record in DocumentDB to have a field called 'embedding_br' which holds the embeddings for the for of the 'overview' field. From here our data ingestion and preparation is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Fetch all documents that have overview field\n",
    "documents_to_update = list(collection.find({'overview': {\"$exists\": True}}))\n",
    "\n",
    "# Define the batch size for processing\n",
    "batch_size = 100  # You can adjust this based on your requirements\n",
    "\n",
    "# Process documents in batches\n",
    "for i in range(0, len(documents_to_update), batch_size):\n",
    "    batch = documents_to_update[i:i + batch_size]\n",
    "\n",
    "    # Generate embeddings for the current batch and store it alongside existing data as new field\n",
    "    for doc in batch:\n",
    "        doc['embedding_br'] = generate_embedding(doc['overview'])\n",
    "\n",
    "    # Update the batch of documents\n",
    "    bulk_operations = [pymongo.ReplaceOne({'_id': doc['_id']}, doc) for doc in batch]\n",
    "    collection.bulk_write(bulk_operations)\n",
    "\n",
    "print(\"Batch processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a text index on the 'overview' field to allow for keyword searching. For more information see: \n",
    "https://docs.aws.amazon.com/documentdb/latest/developerguide/text-search.html\n",
    "\n",
    "Required Parameter: name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_index'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating native text search index\n",
    "\n",
    "collection.create_index ([(\"overview\",\"text\")],name=\"text_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "projection attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projection = {\n",
    "\"_id\":0,\n",
    "\"primary_genre\": 1, \n",
    "\"overview\": 1,\n",
    "\"original_title\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a function that uses takes a keyword to search on the 'overview' field.\n",
    "Parameter required: keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_text(keyword):\n",
    "    results = collection.aggregate([{\"$match\": {\"$text\": {\"$search\": keyword}}},{\"$project\": projection},{\"$limit\": 3}])\n",
    "    return json.dumps(list(results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the function above to search the overview field for a keyword\n",
    "required parameter: keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'primary_genre': 'Comedy', 'original_title': \"Breakfast at Tiffany's\", 'overview': \"Fortune hunter Holly Golightly finds herself captivated by aspiring writer Paul Varjak, who's moved into her building on a wealthy woman's dime. As romance blooms between Paul and Holly, Doc Golightly shows up on the scene, revealing Holly's past.\"}\n",
      "{'primary_genre': 'Romance', 'original_title': 'Grease', 'overview': \"Australian good girl Sandy and greaser Danny fell in love over the summer. But when they unexpectedly discover they're now in the same high school, will they be able to rekindle their romance despite their eccentric friends?\"}\n",
      "{'primary_genre': 'Drama', 'original_title': 'Elizabeth', 'overview': 'The story of the ascension to the throne and the early reign of Queen Elizabeth the First, the endless attempts by her council to marry her off, the Catholic hatred of her and her romance with Lord Robert Dudley.'}\n"
     ]
    }
   ],
   "source": [
    "keyword = \"romance\"\n",
    "text_results = search_text(keyword)\n",
    "for item in eval(text_results):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a vector index on the 'embeddings_br' field. \n",
    "Required parameters:\n",
    "\n",
    "1. similarity\n",
    "2. name\n",
    "\n",
    "For more information see: https://docs.aws.amazon.com/documentdb/latest/developerguide/vector-search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vs_index'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating HNSW vector search index\n",
    "similarity = \"cosine\" #can switch to 'euclidean' or 'dot product'\n",
    "collection.create_index ([(\"embedding_br\",\"vector\")], \n",
    "    vectorOptions= {\n",
    "        \"type\": \"hnsw\", \n",
    "        \"similarity\": similarity,\n",
    "        \"dimensions\": 1536,\n",
    "        \"m\": 16,\n",
    "        \"efConstruction\": 64},\n",
    "    name=\"vs_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a function that utilzies DocumentDB's vector search to perform semantic search\n",
    "Required parameters: keyword/phase\n",
    "For more information see: https://docs.aws.amazon.com/documentdb/latest/developerguide/vector-search.html#w7aac21c11c15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Semantic search function\n",
    "similarity = \"cosine\" #can switch to 'euclidean' or 'dot product' to match the above\n",
    "def search_semantic(keyword):\n",
    "    query = {\"vectorSearch\" : {\"vector\" : generate_embedding(keyword), \"path\": \"embedding_br\", \"similarity\": similarity, \"k\": 3}}\n",
    "    results = collection.aggregate([{'$search': query},{\"$project\": projection}])\n",
    "    return json.dumps(list(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the function above to utilizing vector search of a keyword or phrase. You may compare this with the previous keyword search to see how results may differ.\n",
    "\n",
    "Required Paramter: keyword/phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'primary_genre': 'Drama', 'original_title': 'Closer', 'overview': 'A witty, romantic, and very dangerous love story about chance meetings, instant attractions, and casual betrayals. Two couples disintegrate when they begin destructive adulterous affairs with each other.'}\n",
      "{'primary_genre': 'Crime', 'original_title': 'Thief of Hearts', 'overview': \"A woman trapped in a boring marriage begins an affair with a handsome man who seems able to read her mind. She doesn't know that he has broken into her house and read her diaries, where she has recorded her deepest thoughts and fantasies.\"}\n",
      "{'primary_genre': 'Drama', 'original_title': 'The House of Mirth', 'overview': 'A woman risks losing her chance of happiness with the only man she has ever loved.'}\n"
     ]
    }
   ],
   "source": [
    "keyword_or_phrase = \"romance\" \n",
    "vector_search_results = search_semantic(keyword_or_phrase)\n",
    "for item in eval(vector_search_results):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a hybrid search approach that combines the results of both keyword search and vector search. You can compare the results of this with the the semantic search and keyword search functions above. \n",
    "\n",
    "Required parameter: keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_hybrid(keyword):\n",
    "    results1 = json.loads(search_semantic(keyword))\n",
    "    results2 = json.loads(search_text(keyword))\n",
    "    results1 = results1[:2]\n",
    "    results2 = results2[:1]\n",
    "    seen = set()\n",
    "    combined_results = []\n",
    "    for d in results1 + results2:\n",
    "        t = tuple(sorted(d.items()))\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            combined_results.append(d)\n",
    "    return json.dumps(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"primary_genre\": \"Drama\", \"original_title\": \"Closer\", \"overview\": \"A witty, romantic, and very dangerous love story about chance meetings, instant attractions, and casual betrayals. Two couples disintegrate when they begin destructive adulterous affairs with each other.\"}, {\"primary_genre\": \"Crime\", \"original_title\": \"Thief of Hearts\", \"overview\": \"A woman trapped in a boring marriage begins an affair with a handsome man who seems able to read her mind. She doesn\\'t know that he has broken into her house and read her diaries, where she has recorded her deepest thoughts and fantasies.\"}, {\"primary_genre\": \"Comedy\", \"original_title\": \"Breakfast at Tiffany\\'s\", \"overview\": \"Fortune hunter Holly Golightly finds herself captivated by aspiring writer Paul Varjak, who\\'s moved into her building on a wealthy woman\\'s dime. As romance blooms between Paul and Holly, Doc Golightly shows up on the scene, revealing Holly\\'s past.\"}]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_or_phrase = \"romance\"\n",
    "search_hybrid(keyword_or_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A UI that allows you to easily compare and contrast the different search options. Note that you have to type text BEFORE clicking the buttons. If you get an error, it is because you had a blank search, simply type in the query and click the search of choice to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://af076ffa8a95cbb4dc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://af076ffa8a95cbb4dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_5819/3577953337.py\", line 21, in format_semantic\n",
      "    return format_output(search_semantic(query))\n",
      "  File \"/tmp/ipykernel_5819/409290745.py\", line 4, in search_semantic\n",
      "    query = {\"vectorSearch\" : {\"vector\" : generate_embedding(keyword), \"path\": \"embedding_br\", \"similarity\": similarity, \"k\": 3}}\n",
      "  File \"/tmp/ipykernel_5819/947196752.py\", line 9, in generate_embedding\n",
      "    response = bedrock_client.invoke_model(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py\", line 570, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py\", line 1031, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: expected minLength: 1, actual: 0, please reformat your input and try again.\n"
     ]
    }
   ],
   "source": [
    "# Creating a UI with Gradio\n",
    "def format_output(data):\n",
    "    movies = json.loads(data)\n",
    "    html_content = \"<ul style='list-style: none; padding: 0;'>\"\n",
    "    for movie in movies:\n",
    "        html_content += f\"<li style='margin-bottom: 20px;'><strong>{movie['original_title']}</strong><br/>{movie['overview']}</li>\"\n",
    "    html_content += \"</ul>\"\n",
    "    return html_content\n",
    "\n",
    "with gr.Blocks(gr.themes.Soft()) as demo:\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"## Movie Search Demo\")\n",
    "        query_input = gr.Textbox(label=\"Enter your query here...\")\n",
    "        with gr.Row():\n",
    "            semantic_btn = gr.Button(\"Semantic Search\")\n",
    "            text_btn = gr.Button(\"Text Search\")\n",
    "            hybrid_btn = gr.Button (\"Hybrid Search\")\n",
    "        output = gr.HTML(label=\"Search Results\")\n",
    "\n",
    "    def format_semantic(query):\n",
    "        return format_output(search_semantic(query))\n",
    "\n",
    "    def format_text(query):\n",
    "        return format_output(search_text(query))\n",
    "    \n",
    "    def format_hybrid(query):\n",
    "        return format_output(search_hybrid(query))\n",
    "\n",
    "    semantic_btn.click(format_semantic, inputs=query_input, outputs=output)\n",
    "    text_btn.click(format_text, inputs=query_input, outputs=output)\n",
    "    hybrid_btn.click(format_hybrid, inputs=query_input, outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating our search functions with generative AI to create a more collaborative experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the native inference API to chat with database\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def rag_native_api(question, chat_history):\n",
    "\n",
    "    context_docs = search_semantic(question)\n",
    "\n",
    "    context= context_docs\n",
    "    query= question\n",
    "    chat_history = chat_history\n",
    "    \n",
    "    # Set the model ID, e.g., Llama 3 8b Instruct.\n",
    "    model_id = \"meta.llama3-8b-instruct-v1:0\"\n",
    "\n",
    "    # Define the prompt for the model.\n",
    "    prompt = f\"Given this text extracts:{context} and also consider the history of this chat {json.dumps(chat_history)} Please answer the following question:{query}\"\n",
    "\n",
    "\n",
    "    # Embed the prompt in Llama 3's instruction format.\n",
    "    formatted_prompt = f\"\"\"\n",
    "    <|begin_of_text|>\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    {prompt}\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\"\n",
    "\n",
    "    # Format the request payload using the model's native structure.\n",
    "    native_request = {\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"max_gen_len\": 2048,\n",
    "        \"temperature\": 0,\n",
    "    }\n",
    "\n",
    "    # Convert the native request to JSON.\n",
    "    request = json.dumps(native_request)\n",
    "\n",
    "    try:\n",
    "        # Invoke the model with the request.\n",
    "        response = bedrock_client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Decode the response body.\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = model_response[\"generation\"]\n",
    "    return(response_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://1a4921f3a642e0cc7a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1a4921f3a642e0cc7a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Amazon DocumentDB Powered Chatbot Demo Powered by HNSW Index\n",
    "    \"\"\")\n",
    "    gr.ChatInterface(rag_native_api)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the same RAG capabilities using Langchain\n",
    "for more information see: https://python.langchain.com/docs/integrations/llms/bedrock/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatBedrockConverse(model=\"meta.llama3-8b-instruct-v1:0\", client=bedrock_client, temperature=0, max_tokens=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the langchain API to chat with database\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def rag_langchain(question, chat_history):\n",
    "    context_docs = search_semantic(question)\n",
    "    \n",
    "    # Create a PromptTemplate for the user's question\n",
    "    question_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\", \"query\", \"chat_history\"],\n",
    "        template=\"Given this text extracts:\\n-----\\n{context}\\n-----\\n and also consider the history of this chat {chat_history}\\nPlease answer the following question: {query}\",)\n",
    "\n",
    "    # Create an LLMChain\n",
    "    llm_chain = LLMChain(prompt=question_prompt_template, llm=llm)\n",
    "\n",
    "    # Prepare the input for the LLMChain\n",
    "    input_data = {\n",
    "        \"context\": context_docs,\n",
    "        \"query\": question,\n",
    "        \"chat_history\": chat_history,\n",
    "    }\n",
    "    \n",
    "    # Run the LLMChain\n",
    "    output = llm_chain.invoke(input_data)['text']\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://6d6519c70d7944183c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6d6519c70d7944183c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5819/1395456914.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=question_prompt_template, llm=llm)\n"
     ]
    }
   ],
   "source": [
    "# Creating UI for your Chatbot\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Amazon DocumentDB Powered Chatbot Demo Powered by HNSW Index\n",
    "    \"\"\")\n",
    "    gr.ChatInterface(rag_langchain)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
